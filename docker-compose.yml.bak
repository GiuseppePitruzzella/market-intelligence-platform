services:
  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  # Kafka (with corrected networking)
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://:29092,PLAINTEXT_HOST://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - kafka_data:/var/lib/kafka/data

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  # Logstash (with corrected ports)
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    depends_on:
      - elasticsearch
      - kafka
    volumes:
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline
      - ./config/logstash/settings:/usr/share/logstash/config
      - ./config/logstash/templates:/usr/share/logstash/templates
      - ./scripts:/usr/share/logstash/scripts
    ports:
      - "8082:8080" # Port for Reddit data input
      - "8081:8081" # Port for Twitter data input
      - "9600:9600" # Port for monitoring
    environment:
      - LS_JAVA_OPTS=-Xmx256m -Xms256m
      - NEWSAPI_KEY=${NEWSAPI_KEY}
      - TWITTER_BEARER_TOKEN=${TWITTER_BEARER_TOKEN}
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - ALPHA_VANTAGE_API_KEY=${ALPHA_VANTAGE_API_KEY}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}

  # # Spark Master (with corrected port)
  # spark-master:
  #   image: bitnami/spark:3.5.1
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #   ports:
  #     - "8088:8080" # Spark UI now on http://localhost:8088
  #     - "7077:7077"
  #   volumes:
  #     - ./src/data-processing/spark-jobs:/opt/spark-jobs

  # # Spark Worker
  # spark-worker:
  #   image: bitnami/spark:3.5.1
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=1G
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #   volumes:
  #     - ./src/data-processing/spark-jobs:/opt/spark-jobs

  # # Grafana
  # grafana:
  #   image: grafana/grafana:11.1.0
  #   depends_on:
  #     - elasticsearch
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin123
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #     - ./config/grafana/dashboards:/var/lib/grafana/dashboards
  #     - ./config/grafana/datasources:/etc/grafana/provisioning/datasources

  # # Redis (for caching)
  # redis:
  #   image: redis:7.2-alpine
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redis_data:/data

  # # API Backend
  # api-backend:
  #   build: ./src/api/fastapi-backend
  #   depends_on:
  #     - elasticsearch
  #     - redis
  #     - kafka
  #   ports:
  #     - "8000:8000"
  #   environment:
  #     - ELASTICSEARCH_URL=http://elasticsearch:9200
  #     - REDIS_URL=redis://redis:6379
  #     - KAFKA_BOOTSTRAP_SERVERS=kafka:29092 # Use the internal Kafka port
  #   volumes:
  #     - ./src/api/fastapi-backend:/app

  # # Frontend Dashboard
  # frontend:
  #   build: ./src/frontend/react-dashboard
  #   depends_on:
  #     - api-backend
  #   ports:
  #     - "3001:3000"
  #   environment:
  #     - REACT_APP_API_URL=http://localhost:8000
  #   volumes:
  #     - ./src/frontend/react-dashboard:/app

volumes:
  kafka_data:
  elasticsearch_data:
  grafana_data:
  redis_data: