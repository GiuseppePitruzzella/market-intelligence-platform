input {
  # Alpha Vantage API for stock prices
  http_poller {
    urls => {
      alpha_vantage_intraday => {
        method => get
        url => "https://www.alphavantage.co/query"
        query => {
          "function" => "TIME_SERIES_INTRADAY"
          "symbol" => "AAPL,MSFT,GOOGL,AMZN,TSLA"
          "interval" => "5min"
          "apikey" => "${ALPHA_VANTAGE_API_KEY}"
        }
      }
    }
    request_timeout => 60
    interval => 300
    codec => "json"
    type => "market_data"
    tags => ["alpha_vantage", "stock_prices"]
  }
  
  # Economic indicators
  http_poller {
    urls => {
      economic_indicators => {
        method => get
        url => "https://api.stlouisfed.org/fred/series/observations"
        query => {
          "series_id" => "GDP,UNRATE,FEDFUNDS,CPIAUCSL"
          "api_key" => "${FRED_API_KEY}"
          "file_type" => "json"
          "limit" => "100"
        }
      }
    }
    request_timeout => 60
    interval => 3600
    codec => "json"
    type => "economic_data"
    tags => ["fred", "economic_indicators"]
  }
  
  # Crypto prices (CoinGecko)
  http_poller {
    urls => {
      crypto_prices => {
        method => get
        url => "https://api.coingecko.com/api/v3/simple/price"
        query => {
          "ids" => "bitcoin,ethereum,cardano,polkadot,chainlink"
          "vs_currencies" => "usd"
          "include_24hr_change" => "true"
          "include_market_cap" => "true"
          "include_24hr_vol" => "true"
        }
      }
    }
    request_timeout => 60
    interval => 300
    codec => "json"
    type => "crypto_data"
    tags => ["coingecko", "crypto_prices"]
  }
}

filter {
  # Process Alpha Vantage data
  if [type] == "market_data" {
    # Parse time series data
    ruby {
      code => "
        time_series = event.get('Time Series (5min)')
        if time_series
          time_series.each do |timestamp, data|
            new_event = LogStash::Event.new
            new_event.set('@timestamp', Time.parse(timestamp))
            new_event.set('symbol', event.get('Meta Data')['2. Symbol'])
            new_event.set('open', data['1. open'].to_f)
            new_event.set('high', data['2. high'].to_f)
            new_event.set('low', data['3. low'].to_f)
            new_event.set('close', data['4. close'].to_f)
            new_event.set('volume', data['5. volume'].to_i)
            new_event.set('data_type', 'stock_price')
            new_event.set('source', 'alpha_vantage')
            new_event.tag('stock_data')
            new_event.cancel
          end
        end
      "
    }
  }
  
  # Process crypto data
  if [type] == "crypto_data" {
    ruby {
      code => "
        event.to_hash.each do |symbol, data|
          next if symbol.start_with?('@') or symbol == 'tags' or symbol == 'type'
          
          new_event = LogStash::Event.new
          new_event.set('@timestamp', Time.now)
          new_event.set('symbol', symbol)
          new_event.set('price_usd', data['usd'])
          new_event.set('market_cap_usd', data['usd_market_cap'])
          new_event.set('volume_24h_usd', data['usd_24h_vol'])
          new_event.set('change_24h', data['usd_24h_change'])
          new_event.set('data_type', 'crypto_price')
          new_event.set('source', 'coingecko')
          new_event.tag('crypto_data')
          new_event.cancel
        end
      "
    }
  }
  
  # Calculate technical indicators
  if "stock_data" in [tags] {
    # Moving averages (simplified)
    aggregate {
      task_id => "%{symbol}"
      code => "
        map['prices'] ||= []
        map['prices'] << event.get('close')
        map['prices'] = map['prices'].last(20)  # Keep last 20 prices
        
        if map['prices'].length >= 5
          sma5 = map['prices'].last(5).sum / 5.0
          event.set('sma5', sma5)
        end
        
        if map['prices'].length >= 20
          sma20 = map['prices'].sum / 20.0
          event.set('sma20', sma20)
        end
      "
    }
  }
  
  # Add processing metadata
  mutate {
    add_field => { "ingested_at" => "%{@timestamp}" }
  }
}

output {
  # Send to Kafka for real-time processing
  kafka {
    topic_id => "market-data"
    bootstrap_servers => "kafka:9092"
    codec => json
  }
  
  # Index in Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "market-data-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }
  
  # Debug output
  stdout { 
    codec => rubydebug {
      metadata => false
    }
  }
}